# ğŸ¨ Visualizar Agente en LangGraph Studio

Esta guÃ­a explica cÃ³mo visualizar y depurar tu agente usando **LangGraph Studio** (local) y **LangSmith Dashboard** (agente desplegado).

---

## ğŸ“‹ Opciones Disponibles

### 1. **LangGraph Studio (Local)** ğŸ 
- âœ… VisualizaciÃ³n interactiva de grafos
- âœ… DepuraciÃ³n paso a paso
- âœ… EdiciÃ³n de estado en tiempo real
- âš ï¸ Solo funciona con grafos locales (no Vertex AI directamente)

### 2. **LangSmith Dashboard** ğŸŒ
- âœ… Ver trazas del agente desplegado en Vertex AI
- âœ… Monitoreo de ejecuciones en producciÃ³n
- âœ… AnÃ¡lisis de rendimiento y errores
- âœ… Comparar ejecuciones

---

## ğŸš€ OpciÃ³n 1: LangGraph Studio Local

### Paso 1: Instalar LangGraph CLI

```bash
pip install langgraph-cli[inmem]
```

### Paso 2: Verificar ConfiguraciÃ³n

AsegÃºrate de que `langgraph.json` estÃ© configurado:

```json
{
  "graphs": {
    "lead_qualification": "./src/graphs/lead_graph.py:build_lead_graph",
    "complaint_classification": "./src/graphs/complaint_graph.py:build_complaint_graph"
  },
  "env": ".env",
  "python_version": "3.11",
  "dependencies": ["."]
}
```

### Paso 3: Configurar Variables de Entorno

Crea/actualiza tu `.env`:

```bash
# OpenAI (requerido para LLM)
OPENAI_API_KEY=sk-tu-api-key

# LangSmith (recomendado para tracing)
LANGSMITH_API_KEY=lsv2_tu-api-key
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=belden-sales-agent-local

# Salesforce (mock para desarrollo)
SALESFORCE_MODE=mock

# SAP (mock para desarrollo)
SAP_MODE=mock
```

### Paso 4: Iniciar LangGraph Studio

```bash
# Desde el directorio del proyecto
cd langgraph-salesforce-sap-demo
langgraph dev
```

Esto iniciarÃ¡:
- **LangGraph Studio UI**: `http://localhost:8123`
- **API Server**: `http://localhost:8124`

### Paso 5: Abrir en el Navegador

1. Abre `http://localhost:8123` en tu navegador
2. VerÃ¡s los grafos disponibles:
   - `lead_qualification`
   - `complaint_classification`

### Paso 6: Probar un Grafo

1. Selecciona un grafo (ej: `lead_qualification`)
2. Haz clic en "Run" o "Play"
3. Ingresa datos de prueba:

```json
{
  "lead": {
    "Id": "test-001",
    "Company": "Acme Corp",
    "Title": "CTO",
    "Industry": "Technology",
    "Rating": "Hot",
    "AnnualRevenue": 5000000,
    "NumberOfEmployees": 100,
    "LeadSource": "Website"
  },
  "use_llm": true
}
```

4. Observa la ejecuciÃ³n paso a paso en el visualizador

---

## ğŸŒ OpciÃ³n 2: LangSmith Dashboard (Agente Desplegado)

### Paso 1: Configurar LangSmith en Vertex AI

AsegÃºrate de que las variables de entorno en Vertex AI incluyan:

```bash
LANGSMITH_API_KEY=lsv2_tu-api-key
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=belden-sales-agent-prod
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
```

**Actualizar variables en Vertex AI:**

```bash
# Usar el script de actualizaciÃ³n
python update_env_vars.py
```

O manualmente desde Cloud Console:
1. Ve a Vertex AI â†’ Agent Engine
2. Selecciona tu agente
3. Edita las variables de entorno
4. Agrega las variables de LangSmith

### Paso 2: Ejecutar el Agente Desplegado

Cada vez que ejecutes el agente desplegado, las trazas se enviarÃ¡n automÃ¡ticamente a LangSmith:

```python
from google.cloud import aiplatform
from vertexai.preview import reasoning_engines

# Conectar al agente
agent = reasoning_engines.ReasoningEngine.from_path(
    reasoning_engine_id="TU_AGENT_ID",
    project="TU_PROYECTO",
    location="us-central1"
)

# Ejecutar
result = agent.query(
    action="qualify_lead",
    lead_data={
        "Company": "Acme Corp",
        "Title": "CTO",
        "Industry": "Technology"
    }
)
```

### Paso 3: Ver Trazas en LangSmith

1. Ve a [LangSmith Dashboard](https://smith.langchain.com)
2. Selecciona el proyecto: `belden-sales-agent-prod`
3. VerÃ¡s todas las ejecuciones del agente desplegado
4. Haz clic en una ejecuciÃ³n para ver:
   - **Grafos**: VisualizaciÃ³n del flujo
   - **Nodos**: Cada paso del workflow
   - **LLM Calls**: Prompts y respuestas
   - **Tiempos**: Performance de cada nodo
   - **Errores**: Si hay algÃºn problema

### Paso 4: Filtrar Trazas

En LangSmith puedes filtrar por:
- **Tags**: `vertex-ai`, `lead-qualification`, `complaint-classification`
- **Fecha**: Ãšltimas 24h, 7 dÃ­as, etc.
- **Estado**: Success, Error, etc.
- **Metadata**: `workflow`, `use_llm`, `project`

---

## ğŸ”„ Flujo Recomendado

### Desarrollo Local
1. Usa **LangGraph Studio** para desarrollar y depurar
2. Prueba cambios localmente antes de desplegar
3. Las trazas locales van a `belden-sales-agent-local`

### ProducciÃ³n
1. Despliega a Vertex AI con LangSmith configurado
2. Monitorea ejecuciones en **LangSmith Dashboard**
3. Las trazas de producciÃ³n van a `belden-sales-agent-prod`

---

## ğŸ› ï¸ Scripts Ãštiles

### Ver Trazas Recientes

```bash
# Ver Ãºltimas 10 ejecuciones en LangSmith
python scripts/view_traces.py --limit 10
```

### Comparar Ejecuciones

En LangSmith Dashboard:
1. Selecciona 2+ ejecuciones
2. Haz clic en "Compare"
3. Ve diferencias en prompts, respuestas, tiempos

---

## ğŸ“Š Ejemplo de Traza en LangSmith

Cuando ejecutas el agente, verÃ¡s algo como:

```
ğŸ“¦ Complaint Classification Workflow
â”œâ”€â”€ FetchTicket
â”‚   â””â”€â”€ âœ… Fetched case: 5005g00000XXXXX
â”œâ”€â”€ ClassifyComplaint
â”‚   â”œâ”€â”€ ğŸ¤– LLM Call: classify_complaint_with_llm
â”‚   â”‚   â”œâ”€â”€ Prompt: [Complaint Classification System Prompt]
â”‚   â”‚   â”œâ”€â”€ Response: {is_product_complaint: true, ...}
â”‚   â”‚   â””â”€â”€ Tokens: 450 input, 120 output
â”‚   â””â”€â”€ âœ… Classification: PRODUCT COMPLAINT (switches)
â”œâ”€â”€ DecideAction
â”‚   â””â”€â”€ âœ… Action: email_product_owner
â””â”€â”€ ExecuteActions
    â”œâ”€â”€ ğŸ“§ Email sent: ai_analysis@belden.com
    â””â”€â”€ âœ… Comment posted to Salesforce
```

---

## â“ Troubleshooting

### LangGraph Studio no inicia

```bash
# Verificar que langgraph.json existe
ls -la langgraph.json

# Verificar Python version
python --version  # Debe ser 3.11+

# Reinstalar CLI
pip install --upgrade langgraph-cli[inmem]
```

### No veo trazas en LangSmith

1. Verifica que `LANGSMITH_API_KEY` estÃ© configurado
2. Verifica que `LANGCHAIN_TRACING_V2=true`
3. Revisa los logs del agente en Vertex AI
4. Prueba con un script local primero

### El agente desplegado no envÃ­a trazas

1. Actualiza variables de entorno en Vertex AI
2. Reinicia el agente despuÃ©s de actualizar variables
3. Verifica que el cÃ³digo use `@traceable` decorators

---

## ğŸ“š Referencias

- [LangGraph Studio Docs](https://langchain-ai.github.io/langgraph/tutorials/langgraph-studio/)
- [LangSmith Dashboard](https://docs.smith.langchain.com/)
- [Vertex AI Agent Engine](https://docs.cloud.google.com/agent-builder/agent-engine)

---

## âœ… Checklist

- [ ] LangGraph CLI instalado
- [ ] `langgraph.json` configurado
- [ ] Variables de entorno en `.env`
- [ ] LangGraph Studio corriendo (`langgraph dev`)
- [ ] LangSmith API key configurado
- [ ] Variables de LangSmith en Vertex AI
- [ ] Agente desplegado enviando trazas

---

Â¡Listo! Ahora puedes visualizar y depurar tu agente tanto localmente como en producciÃ³n. ğŸ‰
